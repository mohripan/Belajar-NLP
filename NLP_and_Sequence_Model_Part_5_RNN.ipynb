{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPT/1TZWLpZ5+MvMwSLD7zk",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mohripan/Belajar-NLP/blob/main/NLP_and_Sequence_Model_Part_5_RNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://nlp.stanford.edu/data/glove.42B.300d.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TtSDqw03kChE",
        "outputId": "dcb7e316-49de-4529-8db3-a913ef0bc84d"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-06-11 17:46:40--  https://nlp.stanford.edu/data/glove.42B.300d.zip\n",
            "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: https://downloads.cs.stanford.edu/nlp/data/glove.42B.300d.zip [following]\n",
            "--2023-06-11 17:46:41--  https://downloads.cs.stanford.edu/nlp/data/glove.42B.300d.zip\n",
            "Resolving downloads.cs.stanford.edu (downloads.cs.stanford.edu)... 171.64.64.22\n",
            "Connecting to downloads.cs.stanford.edu (downloads.cs.stanford.edu)|171.64.64.22|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1877800501 (1.7G) [application/zip]\n",
            "Saving to: ‘glove.42B.300d.zip’\n",
            "\n",
            "glove.42B.300d.zip  100%[===================>]   1.75G  4.98MB/s    in 5m 53s  \n",
            "\n",
            "2023-06-11 17:52:34 (5.08 MB/s) - ‘glove.42B.300d.zip’ saved [1877800501/1877800501]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir glove"
      ],
      "metadata": {
        "id": "rYImXJugkTZf"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip -q /content/glove.42B.300d.zip -d glove"
      ],
      "metadata": {
        "id": "nLXltG08kU6y"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy"
      ],
      "metadata": {
        "id": "IC2CUNuSmTZN"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nlp = spacy.load('en_core_web_sm')\n",
        "\n",
        "sentences = ['Believe in yourself and your abilities.',\n",
        "             'Never give up on your dreams, no matter how big or small they may seem.',\n",
        "             'Keep going, even when things get tough.',\n",
        "             'A flock of flamingos.',\n",
        "             'An octopus eight arms.',\n",
        "             'A popsicle on a hot day.']\n",
        "\n",
        "labels = [1, 1, 1, 0, 0, 0]\n",
        "\n",
        "def preprocess_text(text):\n",
        "    # Use SpaCy for preprocessing\n",
        "    doc = nlp(text.lower())\n",
        "    # Use lemmatized version of the word unless it's a pronoun, and remove punctuation and spaces\n",
        "    return [token.lemma_ if token.lemma_ != '-PRON-' else token.text for token in doc if token.is_alpha]"
      ],
      "metadata": {
        "id": "s1hAk7MImVEo"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np"
      ],
      "metadata": {
        "id": "6eTMqgXHoFeG"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_glove_embeddings(path):\n",
        "  embeddings = {}\n",
        "  with open(path, 'r', encoding = 'utf-8') as file:\n",
        "    for line in file:\n",
        "      values = line.strip().split()\n",
        "      word = values[0]\n",
        "      vector = np.array(values[1:], dtype = 'float32')\n",
        "      embeddings[word] = vector\n",
        "    return embeddings\n",
        "\n",
        "glove_embeddings = load_glove_embeddings('/content/glove/glove.42B.300d.txt')\n",
        "\n",
        "print(glove_embeddings['text'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "02FGSpkyoIuS",
        "outputId": "30017406-4ff9-4449-c2d8-f5c9b614d573"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ 1.5670e-01 -2.2406e-01  1.8370e-01  6.4616e-01  2.8366e-01  5.7250e-01\n",
            " -2.9115e+00  7.4529e-01  2.3426e-03  1.4693e-02 -1.1565e-01  1.7561e-01\n",
            "  3.5424e-01 -2.1065e-02 -2.9127e-01 -1.9452e-01  3.1869e-01  6.2684e-01\n",
            "  4.0918e-02  9.2003e-02 -1.9427e-01 -4.9586e-01  1.4694e-01 -2.7903e-01\n",
            " -7.5842e-02 -8.2243e-01  6.2999e-01 -3.9374e-02 -1.8939e-01 -4.3787e-01\n",
            "  3.7667e-01  9.6839e-03  3.3840e-01  2.2171e-01 -2.6935e-01  5.0523e-02\n",
            "  1.1554e-01 -5.1907e-02  4.2702e-01  3.7942e-01 -1.3508e-01  3.7566e-01\n",
            " -4.2238e-01 -2.4842e-01  4.2722e-01 -3.1349e-01  1.0448e-01 -8.6473e-02\n",
            " -7.2372e-03 -5.7965e-01 -7.2468e-02  2.8465e-01 -3.5662e-01 -1.2014e-01\n",
            "  1.7577e-01  3.7206e-01 -1.6491e-01  3.1192e-01 -6.0786e-01 -1.1540e+00\n",
            "  4.9371e-01 -9.9394e-02  5.0650e-01  1.2165e-01  4.8474e-02  4.3641e-01\n",
            " -7.1655e-01 -2.3858e-01 -1.6920e-01 -2.0122e-02  3.3982e-01 -2.1287e-01\n",
            " -2.1000e-02 -4.8859e-01  1.1695e-01 -1.4504e-01 -2.5419e-01 -4.2225e-02\n",
            "  1.2277e-01 -4.4175e-01 -1.1966e+00 -7.9468e-01  3.2766e-01 -5.2362e-01\n",
            "  7.9277e-03  5.3128e-01  1.8185e-01  8.0263e-01 -4.3719e-02  2.0460e-01\n",
            " -4.7694e-01 -9.4509e-02  6.7697e-01 -3.4100e-01 -4.0415e-01  8.2812e-02\n",
            " -2.5476e+00  4.2300e-01  8.4401e-02 -7.7945e-02 -2.5643e-01  2.4561e-01\n",
            "  5.0872e-03  3.4191e-01  7.4862e-02  5.1920e-01  5.8483e-01  4.8965e-01\n",
            " -4.5052e-03  5.6137e-01 -2.1457e-01  3.4569e-01  5.5177e-01 -2.0747e-02\n",
            " -2.9595e-01  2.6678e-01  3.9535e-01 -1.7098e-01 -2.2165e-01 -9.8814e-02\n",
            "  4.2318e-01  2.9076e-01  4.8602e-01  4.2112e-01  3.5531e-01 -2.1144e-01\n",
            " -2.6739e-01 -4.5029e-01  5.6124e-01  5.5764e-01 -2.3274e-01  1.0328e-01\n",
            " -8.5412e-02  1.3117e-02 -2.4811e-01  1.2640e-01  5.9894e-01  4.0915e-01\n",
            "  8.5953e-02  3.1163e-01  4.8507e-01  6.4995e-01  3.0245e-01  8.9251e-02\n",
            "  2.5997e-01 -2.3884e-01 -8.6635e-02 -1.5460e-01  1.4966e-01  6.0852e-02\n",
            " -2.4437e-01 -7.8580e-02 -3.0764e-01 -2.6958e-01  2.3138e-01 -2.9429e-01\n",
            "  5.4035e-02  2.6195e-01  3.5004e-01  5.1415e-01 -3.2653e-01  1.0580e-01\n",
            " -3.2525e-01 -3.7076e-01  1.6235e-01 -1.9557e-01 -5.6160e-01 -1.2679e-01\n",
            " -1.6254e-01  5.7568e-01  3.2454e-01 -1.8234e-01 -2.1008e-01 -6.9691e-01\n",
            " -3.1004e-01  5.3603e-01 -1.6468e-01 -2.0320e-01  4.2744e-02 -1.6950e-01\n",
            " -6.4449e-01  2.7817e-01 -6.0692e-01 -5.9155e-01  3.1888e-01 -2.4221e-01\n",
            "  4.6613e-01 -3.2876e-01 -2.4785e-02  9.0898e-02  6.8997e-02  4.0094e-01\n",
            " -1.3704e-01  6.7901e-01 -2.4055e-01 -4.0616e-01 -2.8584e-01 -3.0973e-01\n",
            "  3.9270e-02 -4.0769e-01  1.6343e-01 -1.3789e-01 -2.1703e-01 -1.2495e-01\n",
            "  1.6003e-01 -3.8265e-01 -3.8094e-01  2.6982e-01  2.0943e-01 -4.6874e-01\n",
            "  4.2959e-01  2.9053e-01  5.4267e-01  4.7370e-01 -2.9660e-01  4.6590e-02\n",
            " -3.6146e-02 -3.8297e-02 -2.4448e-01 -1.7346e-01 -9.1434e-02 -3.5982e-01\n",
            "  9.0012e-02  2.6341e-01 -1.9878e+00  5.8483e-01  3.6724e-01 -6.8432e-01\n",
            " -6.5472e-01 -9.0536e-02 -2.9627e-01  2.2437e-01 -3.1904e-01 -1.4782e-01\n",
            "  1.2676e-01 -2.6533e-01 -5.3187e-01 -1.6014e-01 -4.4419e-01 -5.4313e-01\n",
            "  3.2103e-01  4.3422e-01 -2.9161e-01 -4.9197e-01 -4.5083e-01 -7.9538e-02\n",
            " -1.1462e-01  4.7563e-01 -7.9900e-02  2.5704e-01  9.1847e-03 -3.0229e-01\n",
            "  8.1024e-02  1.9790e-01 -1.9404e-01  6.1991e-02 -3.1954e-01  6.9161e-01\n",
            " -1.8338e-01 -5.4374e-01 -6.8099e-01  6.5913e-01  9.2890e-02  4.5033e-01\n",
            "  2.8691e-02 -9.5047e-01  5.2851e-02 -3.0242e-01  6.0698e-03 -4.7843e-01\n",
            "  2.1780e-01  3.1610e-01 -1.7906e-01  2.7042e-01 -1.2112e-01  7.0370e-02\n",
            "  6.9722e-03  4.4205e-01 -1.1684e-01  2.6266e-01 -3.4326e-01  4.8750e-01\n",
            " -8.0338e-02  3.9390e-01 -2.1462e-01 -6.6869e-02 -4.6814e-01 -3.3387e-02\n",
            "  2.1006e-01  3.4949e-03 -1.3254e-01  4.9666e-02  6.1690e-01 -2.4183e-02\n",
            "  3.8678e-01  7.3845e-02 -1.3352e-01  2.8554e-01 -2.4997e-01  1.1044e-01]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "E9DR1ORhiX53"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class SimpleRNN(nn.Module):\n",
        "  def __init__(self, input_size, hidden_size, output_size):\n",
        "    super(SimpleRNN, self).__init__()\n",
        "    \n",
        "    self.hidden_size = hidden_size\n",
        "\n",
        "    self.i2h = nn.Linear(input_size + hidden_size, hidden_size)\n",
        "    self.i2o = nn.Linear(input_size + hidden_size, output_size)\n",
        "    self.softmax = nn.LogSoftmax(dim = 1)\n",
        "\n",
        "  def forward(self, input, hidden):\n",
        "    combined = torch.cat((input, hidden), 1)\n",
        "    hidden = self.i2h(combined)\n",
        "    output = self.i2o(combined)\n",
        "    output = self.softmax(output)\n",
        "    return output, hidden\n",
        "\n",
        "  def initHidden(self):\n",
        "    return torch.zeros(1, self.hidden_size)"
      ],
      "metadata": {
        "id": "SbtMio2xnbCC"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_hidden = 128\n",
        "n_categories = 1\n",
        "n_dimensions = glove_embeddings['text'].shape[0]\n",
        "\n",
        "rnn = SimpleRNN(n_dimensions, n_hidden, n_categories)"
      ],
      "metadata": {
        "id": "e9eJswBFoA8T"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = optim.Adam(rnn.parameters())\n",
        "criterion = nn.BCEWithLogitsLoss()"
      ],
      "metadata": {
        "id": "kpeGI99mpgR5"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "labels = torch.tensor(labels, dtype = torch.float32).reshape(-1, 1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6MUnypKFrpYL",
        "outputId": "28594a2a-0dc8-458e-8245-ed1d2224abe2"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-64-48009a22e2a9>:1: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  labels = torch.tensor(labels, dtype = torch.float32).reshape(-1, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 5\n",
        "\n",
        "for i in range(num_epochs):\n",
        "  for sentence, label in zip(sentences, labels):\n",
        "    preprocessed_sentence = preprocess_text(sentence)\n",
        "    sentence_vectors = []\n",
        "    for word in preprocessed_sentence:\n",
        "      if word in glove_embeddings:\n",
        "        sentence_vectors.append(glove_embeddings[word])\n",
        "    sentence_vectors = torch.tensor(sentence_vectors)\n",
        "    hidden = rnn.initHidden()\n",
        "    for i in range(sentence_vectors.size()[0]):\n",
        "      optimizer.zero_grad()\n",
        "      output, hidden = rnn(sentence_vectors[i].view(1, -1), hidden)\n",
        "\n",
        "      label_reshaped = torch.clone(label)\n",
        "      label_reshaped = label_reshaped.reshape(-1, 1)\n",
        "\n",
        "      loss = criterion(output, label_reshaped)"
      ],
      "metadata": {
        "id": "v_l5SSSTpshr"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mQNzCaj6q0DU"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}